{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BinaryClassification.ipynb","provenance":[{"file_id":"1uxSMwKFo4R1StJ3rfAGJfmrRlKIQC4Yk","timestamp":1621600535719}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8Z0KV4ninwV","executionInfo":{"status":"ok","timestamp":1622006909014,"user_tz":-420,"elapsed":30462,"user":{"displayName":"fatmajuwita 24","photoUrl":"","userId":"01236051882358317245"}},"outputId":"a8658736-34e4-4ead-8e5c-5b1eae622acf"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e7NyqQuhj6Vw","executionInfo":{"status":"ok","timestamp":1622006915166,"user_tz":-420,"elapsed":3184,"user":{"displayName":"fatmajuwita 24","photoUrl":"","userId":"01236051882358317245"}}},"source":["# mlp for binary classification\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-kgc6fvKkGrY","executionInfo":{"status":"ok","timestamp":1622006961296,"user_tz":-420,"elapsed":620,"user":{"displayName":"fatmajuwita 24","photoUrl":"","userId":"01236051882358317245"}},"outputId":"c6c87453-d3e1-45f0-aea1-5e9697da89c4"},"source":["path = '/content/drive/MyDrive/TugasJST/MLP/Klasifikasi/Binary Classification/ionosphere.csv'\n","df = read_csv(path, header=None)\n","# split into input and output columns\n","X, y = df.values[:, :-1], df.values[:, -1]\n","# ensure all data are floating point values\n","X = X.astype('float32')\n","# encode strings to integer\n","y = LabelEncoder().fit_transform(y)\n","# split into train and test datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","# determine the number of input features\n","n_features = X_train.shape[1]\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["(235, 34) (116, 34) (235,) (116,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ew827nXrzSDi","executionInfo":{"status":"ok","timestamp":1622006982915,"user_tz":-420,"elapsed":6378,"user":{"displayName":"fatmajuwita 24","photoUrl":"","userId":"01236051882358317245"}},"outputId":"e3c5be2a-0e73-4a13-bff2-542b7db8160c"},"source":["# define model\n","model = Sequential()\n","model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n","model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(1, activation='sigmoid'))\n","# compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","# fit the model\n","model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1)\n","model_url = '/content/drive/MyDrive/TugasJST/MLP/Klasifikasi/Binary Classification/klasifikasi_binary.h5'\n","model.save(model_url)\n","print(\"Saved\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","8/8 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.4894\n","Epoch 2/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6426\n","Epoch 3/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6553\n","Epoch 4/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.6936\n","Epoch 5/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7064\n","Epoch 6/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7021\n","Epoch 7/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7106\n","Epoch 8/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7106\n","Epoch 9/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7064\n","Epoch 10/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7106\n","Epoch 11/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7106\n","Epoch 12/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7064\n","Epoch 13/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7277\n","Epoch 14/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7574\n","Epoch 15/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7617\n","Epoch 16/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7660\n","Epoch 17/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7872\n","Epoch 18/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8170\n","Epoch 19/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8340\n","Epoch 20/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8596\n","Epoch 21/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8638\n","Epoch 22/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8638\n","Epoch 23/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8638\n","Epoch 24/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8723\n","Epoch 25/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8936\n","Epoch 26/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8979\n","Epoch 27/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.9064\n","Epoch 28/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.9106\n","Epoch 29/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.9277\n","Epoch 30/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.9277\n","Epoch 31/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.2767 - accuracy: 0.9362\n","Epoch 32/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.9362\n","Epoch 33/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2579 - accuracy: 0.9404\n","Epoch 34/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.9404\n","Epoch 35/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.9362\n","Epoch 36/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9404\n","Epoch 37/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9447\n","Epoch 38/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.9489\n","Epoch 39/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9489\n","Epoch 40/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9532\n","Epoch 41/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9532\n","Epoch 42/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9532\n","Epoch 43/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9574\n","Epoch 44/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1812 - accuracy: 0.9574\n","Epoch 45/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9617\n","Epoch 46/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9617\n","Epoch 47/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1666 - accuracy: 0.9617\n","Epoch 48/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1627 - accuracy: 0.9660\n","Epoch 49/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.9660\n","Epoch 50/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9660\n","Epoch 51/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9617\n","Epoch 52/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9617\n","Epoch 53/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9617\n","Epoch 54/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1403 - accuracy: 0.9660\n","Epoch 55/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9660\n","Epoch 56/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9660\n","Epoch 57/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.9660\n","Epoch 58/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9660\n","Epoch 59/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9660\n","Epoch 60/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9660\n","Epoch 61/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9660\n","Epoch 62/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9660\n","Epoch 63/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.9660\n","Epoch 64/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1121 - accuracy: 0.9660\n","Epoch 65/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.9617\n","Epoch 66/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9617\n","Epoch 67/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.9660\n","Epoch 68/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9617\n","Epoch 69/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9617\n","Epoch 70/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9617\n","Epoch 71/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9617\n","Epoch 72/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9660\n","Epoch 73/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9660\n","Epoch 74/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9660\n","Epoch 75/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9660\n","Epoch 76/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0894 - accuracy: 0.9702\n","Epoch 77/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9702\n","Epoch 78/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.9702\n","Epoch 79/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9745\n","Epoch 80/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.9745\n","Epoch 81/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9745\n","Epoch 82/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9787\n","Epoch 83/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9787\n","Epoch 84/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.9787\n","Epoch 85/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9787\n","Epoch 86/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9787\n","Epoch 87/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9787\n","Epoch 88/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9787\n","Epoch 89/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9787\n","Epoch 90/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9787\n","Epoch 91/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9830\n","Epoch 92/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9872\n","Epoch 93/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9872\n","Epoch 94/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9872\n","Epoch 95/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9872\n","Epoch 96/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9872\n","Epoch 97/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9872\n","Epoch 98/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9830\n","Epoch 99/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9830\n","Epoch 100/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9872\n","Epoch 101/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9872\n","Epoch 102/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9872\n","Epoch 103/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9872\n","Epoch 104/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9872\n","Epoch 105/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9872\n","Epoch 106/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9872\n","Epoch 107/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9872\n","Epoch 108/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9915\n","Epoch 109/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9872\n","Epoch 110/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9915\n","Epoch 111/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9915\n","Epoch 112/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9915\n","Epoch 113/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9915\n","Epoch 114/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9915\n","Epoch 115/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9915\n","Epoch 116/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9872\n","Epoch 117/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9872\n","Epoch 118/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9915\n","Epoch 119/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9915\n","Epoch 120/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9915\n","Epoch 121/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9915\n","Epoch 122/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9915\n","Epoch 123/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9872\n","Epoch 124/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9915\n","Epoch 125/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9915\n","Epoch 126/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9915\n","Epoch 127/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9915\n","Epoch 128/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9915\n","Epoch 129/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9915\n","Epoch 130/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9915\n","Epoch 131/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9915\n","Epoch 132/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9915\n","Epoch 133/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9915\n","Epoch 134/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9915\n","Epoch 135/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9915\n","Epoch 136/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9915\n","Epoch 137/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9915\n","Epoch 138/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9915\n","Epoch 139/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9915\n","Epoch 140/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9915\n","Epoch 141/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9915\n","Epoch 142/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9915\n","Epoch 143/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9915\n","Epoch 144/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9915\n","Epoch 145/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9915\n","Epoch 146/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9915\n","Epoch 147/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9915\n","Epoch 148/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9915\n","Epoch 149/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9915\n","Epoch 150/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9915\n","Saved\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NHIJCYZqkvHJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622007011262,"user_tz":-420,"elapsed":562,"user":{"displayName":"fatmajuwita 24","photoUrl":"","userId":"01236051882358317245"}},"outputId":"e63cd653-6a83-430f-e23f-1be0922f7307"},"source":["loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","print('Test Accuracy: %.3f' % acc)\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Test Accuracy: 0.879\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvtHFnd40dCQ","executionInfo":{"status":"ok","timestamp":1622007014494,"user_tz":-420,"elapsed":574,"user":{"displayName":"fatmajuwita 24","photoUrl":"","userId":"01236051882358317245"}},"outputId":"24cc75f0-ff4a-498c-e93a-f75a37bc8077"},"source":["# make a prediction\n","row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n","yhat = model.predict([row])\n","print('Predicted: %.3f' % yhat)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Predicted: 0.988\n"],"name":"stdout"}]}]}